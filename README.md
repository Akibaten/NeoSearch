HELLOOOOOOO!!

NeoSearch is a search engine for Neocities.org, a site that hosts a static site for you for free!
If you want to skip to installation and usage, feel free. It's at the bottom ._.

# Intro
This is a project I have been working on to create a search engine for the indie website neocities.org.
Neocities is amazing :o It allows you to create a static site, and it does all of the hosting for free.
Not only that, but it has its own site where you can see people's profiles, comment on people's websites,
follow people to get notified when they update their site, and it provides some basic analytics for profiles :3

I love Neocities to death. I am quite disappointed to say that they do not have a search function on their site.
I truly believe in the principles of indie web, and I think that one way we can improve the visibility and
accessibility of indie web is by making it easier to interact with.
Unlike the rest of the internet these days, indie web is still quite a web.
There are all these meandering paths and rabbit holes to fall down, so many
beautiful sites to see, so much to explore... I *love* that.
I think it is a fundamental part of what makes indie web indie web.
I want to make it easier for people to go down these paths.
Giving direct links to pages is pretty boring and really circumvents the whole idea.
I want to make it easier for people to get started on a path they will likely like by
finding sites relevant to them and showing them the sites without links to the direct pages
that have what they want! The adventure is what makes it so fun :D
Unfortunately, such a function does not exist on Neocities which is one of the biggest and most
accessible entry points to the indie web.
Neocities has sort by new, old, views, followers, random etc., but they have no way to help new (or old) users
to find sites that might actually be relevant to them and their interests.
I think if people can go down paths that are relevant to them and their interests, it really
lowers the activation energy needed for someone to start exploring ^_^

Currently, as of version 1 there are only a few features and it only runs in terminal.
A user can search for keywords 
the program goes through a bunch of sites it has crawled and gotten data from and selects sites containing that each of those keywords and compares them.
then the selected sites containing the keyword are ranked according to a ranking list generated by using a super simple algorithm

# How it works
the algorithm is quite simple by design.
I was so enamoured with google's pageRank algorithm (you should learn about it its so cool).
It is truly mathematically beautiful.
I started to think about what does pagerank mean?
pageRank is designed to be a list of id numbers tied to a specific website and an accompanying *rank*
Technically this rank is a probability that if you clicked on a random link on the internet you would end up on that site
Naturally, if a page has a lot of other websites linking to it (inbound links) you are more likely to go to it if you click a random link
So to simplify it a bit, the more people that link to a website the higher that websites rank.

But why would a website have a lot of inbound links?
I think that it is likely because the website has lots of content, is well known, or is high quality or some combination of the three
So it is sort of possible to approximate how worth looking at a website is by looking at its rank

I realized that google had zero analytics about the internet and so it is remarkable that they came up with something so clever.
When I thought about making a search engine for neocities I realized that neocities **does** have analytics!
I thought "could it be possible to use analytics to get close to page rank?", and I built my algorithm around that idea :3
I'm sort of making a neoRank system :P

The current algorithm is super simple.
The neoRank of sites can be found using a linear function that follows this form:

a*(views of a site/total views of all sites) + b*(followers of a site/total followers of all sites)

where a and b are both constants we can change to tweak settings

then all the values of the set are normalized so that all the neoRank values add up to 1

With that calculated, a user can type in the keyword and get search results ranked according to the neoRank set
It's quite simple, and it is *very* fast to calculate of course

In the long run I want to try to keep this specific system as simple as possible.
I could use pageRank, but I feel like its an easy way out given the amount of libraries for it.
However, I want to use analytics to my advantage and make super easy for anyone to calculate their own instance of it.
Perhaps it could be so simple it could even be run client side on a static site.
In the future I want to try to improve results through other methods such as semantic search, sites relations to each other, etc.

If this interests you, and you would like to continue further here is the setup guide below~~~~~

# Installation
neoSearch is currently just a few simple python scripts.
It finds sites, ranks them, crawls and analyzes those sites, and searches through them and returns search results.

## Install Python
neoSearch was made with Python 3.13
I imagine that people reading this probably have python installed already, but just for fun, this is how you install it. Just run these in terminal.

For MacOS:

if you don't already have Homebrew, MacOS's package manage that does not come packaged with MacOS, this is how you install it:

Run this in terminal:
```
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

Then run:
```
brew install python
```

For linux:
Run this in your package manager. You know what to do. I would recommend dnf XD but use whatever you want :P

## Install Python Libraries
The python libraries it uses that aren't included with python are:
+ Requests
+ SQLite3
+ BeautifulSoup4

If you don't have these libraries installed just run this in the terminal (bash or zsh):
```
pip install requests
pip install sqlite3
pip install beautifulsoup4
```

## Build databases
The repo has a sample database you can use with 500 indexed sites as of now.

If you want to make your own databases ther is a more in depth guide and
explanation can be found in /data/DATABASE.md
If you aren't interested just run
```
python3 /scripts/init_crawler.py "however many sites you want to crawl"
python3 /scripts/keyword_indexer.py
python3 /scripts/neoranker.py
```

Now FINALLY you can actually run the whole one single command that lets you look up one word :P

# Usage

To search something just run
```
python3 /scripts/search.py "keywords you want to search"
```

It will show all sites indexed, show all sites that contain all of those keywords, and then rank them and return search results ^_^

Okay thats all lol. More to come in the future. I just wanted to make the repo itself, and I just love writing README's XD
